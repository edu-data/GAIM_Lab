"""
GAIM Lab - ìš©ëŸ‰ ìµœëŒ€ ì˜ìƒ ì¬ë¶„ì„ (ê²€ì‚¬-ì¬ê²€ì‚¬ ì‹ ë¢°ë„ìš©)
20251209_110545.mp4 2ì°¨ ë¶„ì„
"""

import sys
import io
import os
import json
import importlib.util
from pathlib import Path
from datetime import datetime

sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8', errors='replace')

PROJECT_ROOT = Path(__file__).resolve().parent

env_file = PROJECT_ROOT / ".env"
if env_file.exists():
    try:
        from dotenv import load_dotenv
        load_dotenv(env_file)
    except ImportError:
        with open(env_file) as f:
            for line in f:
                if "=" in line and not line.startswith("#"):
                    key, value = line.strip().split("=", 1)
                    os.environ[key] = value.strip('"').strip("'")

print(f"âœ… GOOGLE_API_KEY: {'ìˆìŒ' if os.getenv('GOOGLE_API_KEY') else 'ì—†ìŒ'}")


def load_module_from_path(module_name: str, file_path: Path):
    spec = importlib.util.spec_from_file_location(module_name, file_path)
    module = importlib.util.module_from_spec(spec)
    sys.modules[module_name] = module
    spec.loader.exec_module(module)
    return module


timelapse_module = load_module_from_path(
    "timelapse_analyzer",
    PROJECT_ROOT / "core" / "analyzers" / "timelapse_analyzer.py"
)
TimeLapseAnalyzer = timelapse_module.TimeLapseAnalyzer

sys.path.insert(0, str(PROJECT_ROOT / "backend" / "app"))
from core.evaluator import GAIMLectureEvaluator
from services.report_generator import GAIMReportGenerator


def analyze_single(video_path: Path, output_dir: Path):
    """ë‹¨ì¼ ì˜ìƒ ë¶„ì„"""
    video_name = video_path.stem
    output_dir.mkdir(parents=True, exist_ok=True)

    start_time = datetime.now()

    # Phase 1: TimeLapse ë¶„ì„
    print(f"\nğŸ” [Phase 1/3] ì˜ìƒ ë¶„ì„ ì¤‘...")
    analyzer = TimeLapseAnalyzer(temp_dir=str(output_dir / "cache"))
    vision_results, content_results = analyzer.analyze_video(video_path)
    audio_metrics = analyzer.get_audio_metrics()
    elapsed = analyzer.get_elapsed_time()
    print(f"   âœ… ë¹„ì „ {len(vision_results)}í”„ë ˆì„, ì²˜ë¦¬ì‹œê°„ {elapsed:.1f}s")

    # Phase 1.5: Whisper STT
    transcript = ""
    audio_path = output_dir / "audio.wav"
    try:
        import subprocess
        cmd = ['ffmpeg', '-i', str(video_path), '-ar', '16000', '-ac', '1', str(audio_path), '-loglevel', 'error', '-y']
        subprocess.run(cmd, check=True, capture_output=True)

        text_module = load_module_from_path("text_analyzer", PROJECT_ROOT / "core" / "analyzers" / "text_analyzer.py")
        transcript, segments = text_module.transcribe_audio(str(audio_path), model_size="small")
        if transcript:
            print(f"   ğŸ¤ STT ì™„ë£Œ: {len(transcript)}ì")
            (output_dir / "transcript.txt").write_text(transcript, encoding="utf-8")
    except Exception as e:
        print(f"   âš ï¸ STT ìŠ¤í‚µ: {e}")

    # Phase 2: 7ì°¨ì› í‰ê°€
    print(f"\nğŸ“Š [Phase 2/3] 7ì°¨ì› í‰ê°€ ì¤‘...")
    total_frames = len(vision_results) if vision_results else 0
    eye_ratio = sum(1 for r in vision_results if r.get("face_visible", False)) / total_frames if total_frames > 0 else 0
    gesture_ratio = sum(1 for r in vision_results if r.get("gesture_active", False)) / total_frames if total_frames > 0 else 0
    text_densities = [r.get("text_density", 0) for r in (content_results or []) if r.get("text_density")]

    analysis_data = {
        "vision_metrics": {"eye_contact_ratio": eye_ratio, "gesture_ratio": gesture_ratio, "frame_count": total_frames},
        "vibe_metrics": audio_metrics,
        "content_metrics": {"slide_changes": len(content_results or []), "avg_text_density": sum(text_densities) / len(text_densities) if text_densities else 0},
        "text_metrics": {},
        "transcript": transcript,
    }

    evaluator = GAIMLectureEvaluator()
    evaluation_result = evaluator.evaluate(analysis_data)
    evaluation_dict = evaluator.to_dict(evaluation_result)

    result_path = output_dir / "evaluation_result.json"
    result_path.write_text(json.dumps(evaluation_dict, ensure_ascii=False, indent=2), encoding="utf-8")
    print(f"   âœ… í‰ê°€ ì™„ë£Œ: {evaluation_dict.get('total_score', 0)}ì  ({evaluation_dict.get('grade', 'N/A')})")

    # Phase 3: ë¦¬í¬íŠ¸ ìƒì„±
    print(f"\nğŸ“‹ [Phase 3/3] HTML ë¦¬í¬íŠ¸ ìƒì„± ì¤‘...")
    try:
        gen = GAIMReportGenerator(output_dir=output_dir)
        gen.generate_html_report(evaluation_dict, video_name)
        print(f"   âœ… HTML ë¦¬í¬íŠ¸ ìƒì„± ì™„ë£Œ")
    except Exception as e:
        print(f"   âš ï¸ ë¦¬í¬íŠ¸ ìƒì„± ìŠ¤í‚µ: {e}")

    total_elapsed = (datetime.now() - start_time).total_seconds()

    print("\n" + "=" * 60)
    print("âœ… 2ì°¨ ë¶„ì„ ì™„ë£Œ!")
    print("=" * 60)
    print(f"ğŸ“ ì˜ìƒ: {video_path.name} ({video_path.stat().st_size / 1024 / 1024:.1f} MB)")
    print(f"â±ï¸ ì´ ì†Œìš”: {total_elapsed:.1f}ì´ˆ")
    print(f"ğŸ“Š ì´ì : {evaluation_dict.get('total_score', 0)} / 100ì ")
    print(f"ğŸ“Š ë“±ê¸‰: {evaluation_dict.get('grade', 'N/A')}")

    print(f"\nğŸ“ˆ ì°¨ì›ë³„ ì ìˆ˜:")
    for dim in evaluation_dict.get("dimensions", []):
        name = dim.get("name", "")
        score = dim.get("score", 0)
        max_score = dim.get("max_score", 20)
        pct = dim.get("percentage", 0)
        bar = "â–ˆ" * int(pct / 10) + "â–‘" * (10 - int(pct / 10))
        print(f"   {name}: {score}/{max_score} [{bar}] {pct:.0f}%")

    # 2ì°¨ ê²°ê³¼ ì €ì¥
    root_result_path = PROJECT_ROOT / "test_largest_result_retest.json"
    root_result_path.write_text(json.dumps(evaluation_dict, ensure_ascii=False, indent=2), encoding="utf-8")
    print(f"\nğŸ“„ 2ì°¨ ê²°ê³¼ íŒŒì¼: {root_result_path}")

    return evaluation_dict


if __name__ == "__main__":
    video = PROJECT_ROOT / "video" / "20251209_110545.mp4"

    if not video.exists():
        print(f"âŒ ì˜ìƒì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {video}")
        sys.exit(1)

    print("=" * 60)
    print(f"ğŸ§ª GAIM Lab - ìš©ëŸ‰ ìµœëŒ€ ì˜ìƒ 2ì°¨ ë¶„ì„ (ì¬ê²€ì‚¬)")
    print(f"ğŸ“ ì˜ìƒ: {video.name} ({video.stat().st_size / 1024 / 1024:.1f} MB)")
    print("=" * 60)

    analyze_single(video, PROJECT_ROOT / "output" / "largest_video_retest")
