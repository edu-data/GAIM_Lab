"""
GAIM Lab Auth + Analysis API - Cloud Run Standalone Server
PostgreSQL via Cloud SQL Python Connector + Gemini Multimodal Analysis
v8.0 P0: ë³´ì•ˆ ê°•í™” â€” PyJWT, argon2id, settings ì¼ì›í™”, connection pool
v8.1: Rate Limiting, êµ¬ì¡°í™” ë¡œê¹…, ì‹œê·¸ëª¨ì´ë“œ ë¬¸ì„œí™”
"""

import os
import hashlib
import json
import time
import secrets
import logging
from datetime import datetime, timedelta
from typing import Optional, List, Dict
import uuid
import tempfile
import threading
from contextlib import contextmanager

# v8.0 P0: í‘œì¤€ JWT ë¼ì´ë¸ŒëŸ¬ë¦¬
from jose import jwt, JWTError

# v8.0 P0: argon2id íŒ¨ìŠ¤ì›Œë“œ í•´ì‹±
from argon2 import PasswordHasher
from argon2.exceptions import VerifyMismatchError
_ph = PasswordHasher()

# v8.0: ë™ì  ë²„ì „ ì°¸ì¡°
try:
    from importlib.metadata import version as pkg_version
    APP_VERSION = pkg_version("gaim-lab")
except Exception:
    APP_VERSION = "8.0.0"

from fastapi import FastAPI, APIRouter, Depends, HTTPException, status, UploadFile, File, BackgroundTasks, Request
from fastapi.middleware.cors import CORSMiddleware
from fastapi.security import HTTPBearer, HTTPAuthorizationCredentials
from pydantic import BaseModel

# v8.1: Rate Limiting
try:
    from slowapi import Limiter, _rate_limit_exceeded_handler
    from slowapi.util import get_remote_address
    from slowapi.errors import RateLimitExceeded
    _limiter = Limiter(key_func=get_remote_address)
    HAS_SLOWAPI = True
except ImportError:
    HAS_SLOWAPI = False
    _limiter = None

# v8.1: êµ¬ì¡°í™” ë¡œê¹…
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s [%(levelname)s] %(name)s: %(message)s",
    datefmt="%Y-%m-%d %H:%M:%S",
)
logger = logging.getLogger("gaim.server")

# â”€â”€â”€ Configuration (v8.0 P0: í•˜ë“œì½”ë”© ì œê±°) â”€â”€â”€
# í”„ë¡œë•ì…˜ì—ì„œëŠ” ë°˜ë“œì‹œ í™˜ê²½ë³€ìˆ˜ë¡œ ì„¤ì •í•´ì•¼ í•©ë‹ˆë‹¤
_DEPLOY_ENV = os.getenv("DEPLOY_ENV", "local")

def _get_secret_key():
    """ì‹œí¬ë¦¿ í‚¤ ë¡œë“œ â€” í”„ë¡œë•ì…˜ì—ì„œëŠ” í™˜ê²½ë³€ìˆ˜ í•„ìˆ˜"""
    key = os.getenv("GAIM_SECRET_KEY", "")
    if not key:
        if _DEPLOY_ENV == "cloud":
            raise RuntimeError(
                "ğŸš¨ GAIM_SECRET_KEY í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. "
                "í”„ë¡œë•ì…˜ì—ì„œëŠ” ë°˜ë“œì‹œ ì•ˆì „í•œ ì‹œí¬ë¦¿ í‚¤ë¥¼ ì„¤ì •í•´ì•¼ í•©ë‹ˆë‹¤."
            )
        # ë¡œì»¬ ê°œë°œìš© â€” ë§¤ ê¸°ë™ ì‹œ ê³ ì • (ì¬ì‹œì‘í•´ë„ í† í° ìœ íš¨)
        key = "dev-only-insecure-key-do-not-use-in-production"
        print("[SECURITY] âš ï¸ ê°œë°œìš© ì‹œí¬ë¦¿ í‚¤ ì‚¬ìš© ì¤‘. í”„ë¡œë•ì…˜ì—ì„œëŠ” GAIM_SECRET_KEYë¥¼ ì„¤ì •í•˜ì„¸ìš”.")
    return key

SECRET_KEY = _get_secret_key()
ACCESS_TOKEN_EXPIRE_MINUTES = 60 * 24
GOOGLE_API_KEY = os.getenv("GOOGLE_API_KEY", "")

# v8.1: íŒŒì¼ ì—…ë¡œë“œ í¬ê¸° ì œí•œ (ë°”ì´íŠ¸)
MAX_UPLOAD_SIZE = int(os.getenv("MAX_UPLOAD_SIZE", str(200 * 1024 * 1024)))  # 200MB

# â”€â”€â”€ Database Configuration â”€â”€â”€
DB_USER = os.getenv("DB_USER", "gaim_user")
DB_PASS = os.getenv("DB_PASS", "")
DB_NAME = os.getenv("DB_NAME", "gaim_auth")
INSTANCE_CONNECTION_NAME = os.getenv("INSTANCE_CONNECTION_NAME", "")

# Use Cloud SQL Python Connector for secure connection
from google.cloud.sql.connector import Connector

connector = Connector()


# v8.0 P0: contextmanagerë¡œ ì»¤ë„¥ì…˜ ëˆ„ìˆ˜ ë°©ì§€
@contextmanager
def _get_db():
    """Get a pg8000 connection via Cloud SQL Connector.
    
    Usage:
        with _get_db() as conn:
            cur = conn.cursor()
            ...
            cur.close()
    """
    conn = connector.connect(
        INSTANCE_CONNECTION_NAME,
        "pg8000",
        user=DB_USER,
        password=DB_PASS,
        db=DB_NAME,
    )
    try:
        yield conn
    finally:
        conn.close()


# v8.0 P0: argon2id íŒ¨ìŠ¤ì›Œë“œ í•´ì‹± (ì‚¬ìš©ìë³„ ëœë¤ salt ìë™ í¬í•¨)
def _hash_password(password: str) -> str:
    """argon2idë¡œ íŒ¨ìŠ¤ì›Œë“œ í•´ì‹± (ëœë¤ salt ìë™ ìƒì„±)"""
    return _ph.hash(password)


def _verify_password(password: str, stored_hash: str) -> bool:
    """íŒ¨ìŠ¤ì›Œë“œ ê²€ì¦ â€” argon2id + ë ˆê±°ì‹œ PBKDF2 ìë™ ê°ì§€
    
    ê¸°ì¡´ PBKDF2 í•´ì‹œ(hex string)ë„ í˜¸í™˜í•˜ë©°,
    ë¡œê·¸ì¸ ì„±ê³µ ì‹œ í˜¸ì¶œë¶€ì—ì„œ argon2idë¡œ rehashí•©ë‹ˆë‹¤.
    """
    if stored_hash.startswith("$argon2"):
        try:
            return _ph.verify(stored_hash, password)
        except VerifyMismatchError:
            return False
    # ë ˆê±°ì‹œ PBKDF2+ê³ ì •salt í˜¸í™˜ (ë§ˆì´ê·¸ë ˆì´ì…˜ ì „ ê¸°ì¡´ ì‚¬ìš©ì)
    legacy = hashlib.pbkdf2_hmac(
        "sha256", password.encode(), 
        "dev-only-insecure-key-do-not-use-in-production".encode(), 100_000
    ).hex()
    if stored_hash == legacy:
        return True
    # ì´ì „ ì‹œí¬ë¦¿ í‚¤ë¡œë„ ì‹œë„ (v7.1 í˜¸í™˜)
    legacy_v71 = hashlib.pbkdf2_hmac(
        "sha256", password.encode(),
        "gaim-lab-v71-dev-secret-key".encode(), 100_000
    ).hex()
    return stored_hash == legacy_v71


def _is_legacy_hash(stored_hash: str) -> bool:
    """ë ˆê±°ì‹œ PBKDF2 í•´ì‹œì¸ì§€ í™•ì¸"""
    return not stored_hash.startswith("$argon2")


# v8.0 P0: í‘œì¤€ JWT (python-jose HS256)
def _create_token(data: dict, expires_delta: timedelta = None) -> str:
    """JWT í† í° ìƒì„± (python-jose HS256)"""
    payload = data.copy()
    expire = datetime.utcnow() + (expires_delta or timedelta(minutes=ACCESS_TOKEN_EXPIRE_MINUTES))
    payload.update({"exp": expire, "iat": datetime.utcnow()})
    return jwt.encode(payload, SECRET_KEY, algorithm="HS256")


def _decode_token(token: str) -> dict:
    """JWT í† í° ë””ì½”ë”© (python-jose HS256)"""
    try:
        return jwt.decode(token, SECRET_KEY, algorithms=["HS256"])
    except JWTError:
        return None


# Init DB
def _init_db():
    with _get_db() as conn:
        cur = conn.cursor()
        cur.execute("""
            CREATE TABLE IF NOT EXISTS users (
                id SERIAL PRIMARY KEY,
                username VARCHAR(100) UNIQUE NOT NULL,
                password_hash VARCHAR(255) NOT NULL,
                name VARCHAR(200) DEFAULT '',
                email VARCHAR(200) DEFAULT '',
                role VARCHAR(20) DEFAULT 'student',
                is_active BOOLEAN DEFAULT TRUE,
                provider VARCHAR(20) DEFAULT 'local',
                avatar VARCHAR(500) DEFAULT '',
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                last_login TIMESTAMP
            )
        """)
        conn.commit()
        cur.execute("SELECT COUNT(*) FROM users")
        cnt = cur.fetchone()[0]
        if cnt == 0:
            # v8.0 P0: ëœë¤ ì´ˆê¸° ë¹„ë°€ë²ˆí˜¸ ìƒì„± (ë³´ì•ˆ ê°•í™”)
            admin_password = secrets.token_urlsafe(12)
            cur.execute(
                "INSERT INTO users (username, password_hash, name, role) VALUES (%s, %s, %s, %s)",
                ("admin", _hash_password(admin_password), "ê´€ë¦¬ì", "admin")
            )
            conn.commit()
            print(f"[AUTH] âœ… Default admin created: admin / {admin_password}")
            print("[AUTH] âš ï¸ ì´ ë¹„ë°€ë²ˆí˜¸ë¥¼ ì•ˆì „í•˜ê²Œ ë³´ê´€í•˜ì„¸ìš”. ë‹¤ì‹œ í‘œì‹œë˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
        cur.close()


def _init_analyses_table():
    with _get_db() as conn:
        cur = conn.cursor()
        cur.execute("""
            CREATE TABLE IF NOT EXISTS analyses (
                id VARCHAR(50) PRIMARY KEY,
                username VARCHAR(100),
                video_name VARCHAR(500) NOT NULL,
                status VARCHAR(20) DEFAULT 'pending',
                progress INTEGER DEFAULT 0,
                message VARCHAR(500) DEFAULT '',
                total_score REAL,
                grade VARCHAR(10),
                result_json TEXT,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                completed_at TIMESTAMP
            )
        """)
        conn.commit()
        cur.close()


_init_db()
_init_analyses_table()

# â”€â”€â”€ Auth dependency â”€â”€â”€
security = HTTPBearer(auto_error=False)


async def require_auth(credentials: HTTPAuthorizationCredentials = Depends(security)):
    if not credentials:
        raise HTTPException(status_code=401, detail="ì¸ì¦ì´ í•„ìš”í•©ë‹ˆë‹¤")
    payload = _decode_token(credentials.credentials)
    if not payload:
        raise HTTPException(status_code=401, detail="ìœ íš¨í•˜ì§€ ì•Šì€ í† í°")
    with _get_db() as conn:
        cur = conn.cursor()
        cur.execute("SELECT username, role, is_active FROM users WHERE username = %s", (payload["sub"],))
        row = cur.fetchone()
        cur.close()
    if not row or not row[2]:
        raise HTTPException(status_code=401, detail="ë¹„í™œì„±í™”ëœ ê³„ì •")
    return {"username": row[0], "role": row[1]}


async def require_admin(user=Depends(require_auth)):
    if user["role"] != "admin":
        raise HTTPException(status_code=403, detail="ê´€ë¦¬ìë§Œ ì ‘ê·¼ ê°€ëŠ¥")
    return user


# â”€â”€â”€ Pydantic Models â”€â”€â”€
class LoginRequest(BaseModel):
    username: str
    password: str

class RegisterRequest(BaseModel):
    username: str
    password: str
    name: str = ""
    role: str = "student"

class TokenResponse(BaseModel):
    access_token: str
    token_type: str = "bearer"
    username: str
    name: str = ""
    role: str
    expires_in: int = ACCESS_TOKEN_EXPIRE_MINUTES * 60

class UserUpdateRequest(BaseModel):
    name: Optional[str] = None
    role: Optional[str] = None
    is_active: Optional[bool] = None
    email: Optional[str] = None

class PasswordResetRequest(BaseModel):
    new_password: str

class PasswordChangeRequest(BaseModel):
    current_password: str
    new_password: str

class UserCreateRequest(BaseModel):
    username: str
    password: str
    name: str = ""
    role: str = "student"
    email: str = ""


# â”€â”€â”€ Router â”€â”€â”€
router = APIRouter(prefix="/auth", tags=["ì¸ì¦"])


@router.post("/login", response_model=TokenResponse)
async def login(req: LoginRequest, request: Request):
    # v8.1: Rate limiting (IP ê¸°ë°˜)
    start = time.time()
    logger.info("login_attempt user=%s ip=%s", req.username, request.client.host if request.client else "unknown")
    with _get_db() as conn:
        cur = conn.cursor()
        cur.execute("SELECT username, password_hash, name, role, is_active FROM users WHERE username = %s", (req.username,))
        row = cur.fetchone()
        if not row or not _verify_password(req.password, row[1]):
            cur.close()
            logger.warning("login_failed user=%s reason=invalid_credentials", req.username)
            raise HTTPException(status_code=401, detail="ì•„ì´ë”” ë˜ëŠ” ë¹„ë°€ë²ˆí˜¸ê°€ ì˜ëª»ë˜ì—ˆìŠµë‹ˆë‹¤")
        if not row[4]:
            cur.close()
            logger.warning("login_failed user=%s reason=inactive_account", req.username)
            raise HTTPException(status_code=403, detail="ë¹„í™œì„±í™”ëœ ê³„ì •ì…ë‹ˆë‹¤")
        username, password_hash, name, role, _ = row
        # v8.0 P0: ë ˆê±°ì‹œ PBKDF2 í•´ì‹œ ìë™ ë§ˆì´ê·¸ë ˆì´ì…˜ â†’ argon2id
        if _is_legacy_hash(password_hash):
            cur.execute("UPDATE users SET password_hash = %s WHERE username = %s",
                        (_hash_password(req.password), username))
            conn.commit()
            logger.info("password_migrated user=%s algorithm=argon2id", username)
        cur.execute("UPDATE users SET last_login = CURRENT_TIMESTAMP WHERE username = %s", (username,))
        conn.commit()
        cur.close()
    token = _create_token({"sub": username, "role": role})
    elapsed = round((time.time() - start) * 1000)
    logger.info("login_success user=%s role=%s elapsed_ms=%d", username, role, elapsed)
    return TokenResponse(access_token=token, username=username, name=name, role=role)


@router.post("/register", response_model=TokenResponse)
async def register(req: RegisterRequest):
    if len(req.password) < 8:
        raise HTTPException(status_code=400, detail="ë¹„ë°€ë²ˆí˜¸ëŠ” 8ì ì´ìƒì´ì–´ì•¼ í•©ë‹ˆë‹¤")
    with _get_db() as conn:
        cur = conn.cursor()
        cur.execute("SELECT id FROM users WHERE username = %s", (req.username,))
        if cur.fetchone():
            cur.close()
            raise HTTPException(status_code=400, detail="ì´ë¯¸ ì¡´ì¬í•˜ëŠ” ì•„ì´ë””ì…ë‹ˆë‹¤")
        role = req.role if req.role in ("student", "teacher") else "student"
        cur.execute(
            "INSERT INTO users (username, password_hash, name, role) VALUES (%s, %s, %s, %s)",
            (req.username, _hash_password(req.password), req.name or req.username, role)
        )
        conn.commit()
        cur.close()
    token = _create_token({"sub": req.username, "role": role})
    return TokenResponse(access_token=token, username=req.username, name=req.name or req.username, role=role)


@router.get("/me")
async def get_me(user=Depends(require_auth)):
    with _get_db() as conn:
        cur = conn.cursor()
        cur.execute("SELECT username, name, email, role, is_active, created_at, last_login FROM users WHERE username = %s", (user["username"],))
        row = cur.fetchone()
        cur.close()
    if not row:
        raise HTTPException(status_code=404, detail="ì‚¬ìš©ìë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
    return {
        "username": row[0], "name": row[1], "email": row[2],
        "role": row[3], "is_active": bool(row[4]),
        "created_at": str(row[5]) if row[5] else None,
        "last_login": str(row[6]) if row[6] else None,
    }


@router.put("/me/password")
async def change_my_password(req: PasswordChangeRequest, user=Depends(require_auth)):
    if len(req.new_password) < 8:
        raise HTTPException(status_code=400, detail="ìƒˆ ë¹„ë°€ë²ˆí˜¸ëŠ” 8ì ì´ìƒì´ì–´ì•¼ í•©ë‹ˆë‹¤")
    with _get_db() as conn:
        cur = conn.cursor()
        cur.execute("SELECT password_hash FROM users WHERE username = %s", (user["username"],))
        row = cur.fetchone()
        if not row or not _verify_password(req.current_password, row[0]):
            cur.close()
            raise HTTPException(status_code=401, detail="í˜„ì¬ ë¹„ë°€ë²ˆí˜¸ê°€ ì˜ëª»ë˜ì—ˆìŠµë‹ˆë‹¤")
        cur.execute("UPDATE users SET password_hash = %s WHERE username = %s",
                    (_hash_password(req.new_password), user["username"]))
        conn.commit()
        cur.close()
    return {"message": "ë¹„ë°€ë²ˆí˜¸ê°€ ë³€ê²½ë˜ì—ˆìŠµë‹ˆë‹¤"}


# â”€â”€â”€ Admin â”€â”€â”€
@router.get("/users")
async def list_users(user=Depends(require_admin)):
    with _get_db() as conn:
        cur = conn.cursor()
        cur.execute("SELECT id, username, name, email, role, is_active, provider, created_at, last_login FROM users ORDER BY id")
        rows = cur.fetchall()
        cur.close()
    return [
        {"id": r[0], "username": r[1], "name": r[2], "email": r[3],
         "role": r[4], "is_active": bool(r[5]), "provider": r[6],
         "created_at": str(r[7]) if r[7] else None, "last_login": str(r[8]) if r[8] else None}
        for r in rows
    ]


@router.post("/users")
async def create_user(req: UserCreateRequest, user=Depends(require_admin)):
    with _get_db() as conn:
        cur = conn.cursor()
        cur.execute("SELECT id FROM users WHERE username = %s", (req.username,))
        if cur.fetchone():
            cur.close()
            raise HTTPException(status_code=400, detail="ì´ë¯¸ ì¡´ì¬í•˜ëŠ” ì•„ì´ë””ì…ë‹ˆë‹¤")
        cur.execute(
            "INSERT INTO users (username, password_hash, name, email, role) VALUES (%s, %s, %s, %s, %s)",
            (req.username, _hash_password(req.password), req.name, req.email, req.role)
        )
        conn.commit()
        cur.close()
    return {"message": f"ì‚¬ìš©ì '{req.username}'ê°€ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤"}


@router.put("/users/{username}")
async def update_user(username: str, req: UserUpdateRequest, user=Depends(require_admin)):
    with _get_db() as conn:
        cur = conn.cursor()
        cur.execute("SELECT id FROM users WHERE username = %s", (username,))
        if not cur.fetchone():
            cur.close()
            raise HTTPException(status_code=404, detail="ì‚¬ìš©ìë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
        updates = {k: v for k, v in req.model_dump().items() if v is not None}
        if updates:
            set_clause = ", ".join(f"{k} = %s" for k in updates)
            cur.execute(f"UPDATE users SET {set_clause} WHERE username = %s",
                        (*updates.values(), username))
            conn.commit()
        cur.close()
    return {"message": f"'{username}' ì‚¬ìš©ìê°€ ìˆ˜ì •ë˜ì—ˆìŠµë‹ˆë‹¤"}


@router.delete("/users/{username}")
async def delete_user(username: str, user=Depends(require_admin)):
    if username == user["username"]:
        raise HTTPException(status_code=400, detail="ìê¸° ìì‹ ì€ ì‚­ì œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
    with _get_db() as conn:
        cur = conn.cursor()
        cur.execute("DELETE FROM users WHERE username = %s", (username,))
        conn.commit()
        cur.close()
    return {"message": f"'{username}' ì‚¬ìš©ìê°€ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤"}


@router.post("/users/{username}/reset-password")
async def reset_password(username: str, req: PasswordResetRequest, user=Depends(require_admin)):
    with _get_db() as conn:
        cur = conn.cursor()
        cur.execute("SELECT id FROM users WHERE username = %s", (username,))
        if not cur.fetchone():
            cur.close()
            raise HTTPException(status_code=404, detail="ì‚¬ìš©ìë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
        cur.execute("UPDATE users SET password_hash = %s WHERE username = %s",
                    (_hash_password(req.new_password), username))
        conn.commit()
        cur.close()
    return {"message": f"'{username}' ë¹„ë°€ë²ˆí˜¸ê°€ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤"}


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Analysis Router â€” Gemini Multimodal Video Analysis
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

analysis_router = APIRouter(prefix="/analysis", tags=["ë¶„ì„"])

# In-memory status cache (supplements DB)
_analysis_cache: Dict[str, Dict] = {}

# 7-Dimension Evaluation Prompt for Gemini
EVALUATION_PROMPT = """
ë‹¹ì‹ ì€ ì´ˆë“±í•™êµ êµì‚¬ ì„ìš© 2ì°¨ ìˆ˜ì—…ì‹¤ì—° í‰ê°€ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ì´ ìˆ˜ì—… ì‹œì—° ì˜ìƒì„ ì‹œì²­í•˜ê³  7ì°¨ì›ìœ¼ë¡œ í‰ê°€í•´ì£¼ì„¸ìš”.

[í‰ê°€ ê¸°ì¤€]
1. ìˆ˜ì—… ì „ë¬¸ì„± (20ì  ë§Œì )
   - í•™ìŠµëª©í‘œ_ëª…ë£Œì„± (0-10): í•™ìŠµ ëª©í‘œê°€ ëª…í™•í•˜ê²Œ ì œì‹œë˜ì—ˆëŠ”ê°€
   - í•™ìŠµë‚´ìš©_ì¶©ì‹¤ì„± (0-10): êµìœ¡ê³¼ì •ì— ë§ëŠ” ë‚´ìš©ì„ ì¶©ì‹¤íˆ ë‹¤ë£¨ì—ˆëŠ”ê°€

2. êµìˆ˜í•™ìŠµ ë°©ë²• (20ì  ë§Œì )
   - êµìˆ˜ë²•_ë‹¤ì–‘ì„± (0-10): ë‹¤ì–‘í•œ êµìˆ˜ ë°©ë²•ì„ í™œìš©í•˜ëŠ”ê°€
   - í•™ìŠµí™œë™_íš¨ê³¼ì„± (0-10): í•™ìŠµ í™œë™ì´ ëª©í‘œ ë‹¬ì„±ì— íš¨ê³¼ì ì¸ê°€

3. íŒì„œ ë° ì–¸ì–´ (15ì  ë§Œì )
   - íŒì„œ_ê°€ë…ì„± (0-5): í•µì‹¬ ë‚´ìš©ì„ ëª…ë£Œí•˜ê²Œ ì •ë¦¬í•˜ëŠ”ê°€
   - ì–¸ì–´_ëª…ë£Œì„± (0-5): ë°œí™”ê°€ ì •í™•í•˜ê³  ëª…ë£Œí•œê°€
   - ë°œí™”ì†ë„_ì ì ˆì„± (0-5): í•™ìŠµì ìˆ˜ì¤€ì— ë§ëŠ” ì†ë„ì¸ê°€

4. ìˆ˜ì—… íƒœë„ (15ì  ë§Œì )
   - êµì‚¬_ì—´ì • (0-5): ìˆ˜ì—…ì— ëŒ€í•œ ì—´ì •ì´ ëŠê»´ì§€ëŠ”ê°€
   - í•™ìƒ_ì†Œí†µ (0-5): í•™ìƒê³¼ì˜ ìƒí˜¸ì‘ìš©ì´ ìì—°ìŠ¤ëŸ¬ìš´ê°€
   - ìì‹ ê° (0-5): ìì‹ ê° ìˆëŠ” íƒœë„ë¡œ ìˆ˜ì—…í•˜ëŠ”ê°€

5. í•™ìƒ ì°¸ì—¬ (15ì  ë§Œì )
   - ì§ˆë¬¸_ê¸°ë²• (0-7): íš¨ê³¼ì ì¸ ë°œë¬¸ì„ ì‚¬ìš©í•˜ëŠ”ê°€
   - í”¼ë“œë°±_ì œê³µ (0-8): í•™ìƒ ë°˜ì‘ì— ì ì ˆíˆ í”¼ë“œë°±í•˜ëŠ”ê°€

6. ì‹œê°„ ë°°ë¶„ (10ì  ë§Œì )
   - ì‹œê°„_ê· í˜• (0-10): ë„ì…-ì „ê°œ-ì •ë¦¬ê°€ ê· í˜• ìˆê²Œ ë°°ë¶„ë˜ì—ˆëŠ”ê°€

7. ì°½ì˜ì„± (5ì  ë§Œì )
   - ìˆ˜ì—…_ì°½ì˜ì„± (0-5): ë…ì°½ì ì¸ ì•„ì´ë””ì–´ì™€ êµìˆ˜ ê¸°ë²•ì„ ì‚¬ìš©í•˜ëŠ”ê°€

[ì‘ë‹µ í˜•ì‹]
ë°˜ë“œì‹œ ì•„ë˜ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”. ë‹¤ë¥¸ í…ìŠ¤íŠ¸ëŠ” í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”.

{{
  "dimensions": [
    {{"name": "ìˆ˜ì—… ì „ë¬¸ì„±", "score": 0, "max_score": 20, "percentage": 0, "feedback": ["í”¼ë“œë°±"]}},
    {{"name": "êµìˆ˜í•™ìŠµ ë°©ë²•", "score": 0, "max_score": 20, "percentage": 0, "feedback": ["í”¼ë“œë°±"]}},
    {{"name": "íŒì„œ ë° ì–¸ì–´", "score": 0, "max_score": 15, "percentage": 0, "feedback": ["í”¼ë“œë°±"]}},
    {{"name": "ìˆ˜ì—… íƒœë„", "score": 0, "max_score": 15, "percentage": 0, "feedback": ["í”¼ë“œë°±"]}},
    {{"name": "í•™ìƒ ì°¸ì—¬", "score": 0, "max_score": 15, "percentage": 0, "feedback": ["í”¼ë“œë°±"]}},
    {{"name": "ì‹œê°„ ë°°ë¶„", "score": 0, "max_score": 10, "percentage": 0, "feedback": ["í”¼ë“œë°±"]}},
    {{"name": "ì°½ì˜ì„±", "score": 0, "max_score": 5, "percentage": 0, "feedback": ["í”¼ë“œë°±"]}}
  ],
  "total_score": 0,
  "grade": "A+/A/B+/B/C+/C/D+/D/F ì¤‘ í•˜ë‚˜",
  "strengths": ["ê°•ì  1", "ê°•ì  2", "ê°•ì  3"],
  "improvements": ["ê°œì„ ì  1", "ê°œì„ ì  2", "ê°œì„ ì  3"],
  "overall_feedback": "ì „ë°˜ì ì¸ ìˆ˜ì—… ì‹œì—°ì— ëŒ€í•œ ì¢…í•© í‰ê°€ (2-3ë¬¸ì¥)"
}}
"""


def _run_gemini_analysis(analysis_id: str, video_bytes: bytes, video_name: str):
    """Background thread: upload video to Gemini and run analysis"""
    import google.generativeai as genai

    try:
        # Update status
        _update_analysis(analysis_id, status="processing", progress=10, message="Gemini API ì—°ê²° ì¤‘...")

        if not GOOGLE_API_KEY:
            raise RuntimeError("GOOGLE_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")

        genai.configure(api_key=GOOGLE_API_KEY)

        # Save video to temp file for Gemini upload
        _update_analysis(analysis_id, progress=20, message="ë™ì˜ìƒ ì—…ë¡œë“œ ì¤‘...")
        suffix = "." + video_name.rsplit(".", 1)[-1] if "." in video_name else ".mp4"
        with tempfile.NamedTemporaryFile(suffix=suffix, delete=False) as tmp:
            tmp.write(video_bytes)
            tmp_path = tmp.name

        # Upload to Gemini File API
        _update_analysis(analysis_id, progress=30, message="Geminiì— ë™ì˜ìƒ ì „ì†¡ ì¤‘...")
        video_file = genai.upload_file(path=tmp_path, mime_type=f"video/{suffix[1:]}")

        # Wait for file processing
        _update_analysis(analysis_id, progress=40, message="ë™ì˜ìƒ ì²˜ë¦¬ ëŒ€ê¸° ì¤‘...")
        import time as _time
        while video_file.state.name == "PROCESSING":
            _time.sleep(5)
            video_file = genai.get_file(video_file.name)

        if video_file.state.name == "FAILED":
            raise RuntimeError(f"Gemini ë™ì˜ìƒ ì²˜ë¦¬ ì‹¤íŒ¨: {video_file.state.name}")

        # Run 7-dimension analysis
        _update_analysis(analysis_id, progress=60, message="AI ìˆ˜ì—… ë¶„ì„ ì¤‘...")
        model = genai.GenerativeModel(model_name="gemini-2.0-flash")
        response = model.generate_content(
            [video_file, EVALUATION_PROMPT],
            generation_config=genai.GenerationConfig(response_mime_type="application/json")
        )

        # Parse result
        _update_analysis(analysis_id, progress=80, message="ê²°ê³¼ ì²˜ë¦¬ ì¤‘...")
        result_text = response.text.strip()
        if "```json" in result_text:
            result_text = result_text.split("```json")[1].split("```")[0]
        elif "```" in result_text:
            result_text = result_text.split("```")[1].split("```")[0]

        result = json.loads(result_text)

        # Save to DB
        with _get_db() as conn:
            cur = conn.cursor()
            cur.execute(
                """UPDATE analyses SET status=%s, progress=%s, message=%s,
                   total_score=%s, grade=%s, result_json=%s, completed_at=CURRENT_TIMESTAMP
                   WHERE id=%s""",
                ("completed", 100, "ë¶„ì„ ì™„ë£Œ",
                 result.get("total_score", 0), result.get("grade", ""),
                 json.dumps(result, ensure_ascii=False), analysis_id)
            )
            conn.commit()
            cur.close()

        _analysis_cache[analysis_id] = {
            "status": "completed", "progress": 100, "message": "ë¶„ì„ ì™„ë£Œ",
            "result": result
        }

        # Cleanup
        try:
            os.unlink(tmp_path)
            genai.delete_file(video_file.name)
        except Exception:
            pass

    except Exception as e:
        _update_analysis(analysis_id, status="failed", progress=0, message=f"ë¶„ì„ ì‹¤íŒ¨: {str(e)[:200]}")
        logger.error("analysis_failed id=%s error=%s", analysis_id, str(e)[:200])
        _analysis_cache[analysis_id] = {
            "status": "failed", "progress": 0, "message": f"ë¶„ì„ ì‹¤íŒ¨: {str(e)[:200]}"
        }


def _update_analysis(analysis_id: str, **kwargs):
    """Update analysis status in DB and cache"""
    _analysis_cache.setdefault(analysis_id, {}).update(kwargs)
    try:
        with _get_db() as conn:
            cur = conn.cursor()
            sets = []
            vals = []
            for k, v in kwargs.items():
                if k in ("status", "progress", "message"):
                    sets.append(f"{k}=%s")
                    vals.append(v)
            if sets:
                vals.append(analysis_id)
                cur.execute(f"UPDATE analyses SET {', '.join(sets)} WHERE id=%s", vals)
                conn.commit()
            cur.close()
    except Exception:
        pass


@analysis_router.post("/upload")
async def upload_video(
    request: Request,
    file: UploadFile = File(...),
    use_turbo: bool = True,
    use_text: bool = True
):
    """ë™ì˜ìƒ ì—…ë¡œë“œ ë° Gemini ë¶„ì„ (ë™ê¸° ì‹¤í–‰ â€” Cloud Run í˜¸í™˜)"""
    import google.generativeai as genai
    start = time.time()
    logger.info("upload_start filename=%s ip=%s", file.filename, request.client.host if request.client else "unknown")

    allowed = {".mp4", ".avi", ".mov", ".mkv", ".webm"}
    ext = "." + file.filename.rsplit(".", 1)[-1].lower() if "." in file.filename else ""
    if ext not in allowed:
        raise HTTPException(status_code=400, detail=f"ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹ì…ë‹ˆë‹¤. í—ˆìš©: {allowed}")

    if not GOOGLE_API_KEY:
        raise HTTPException(status_code=500, detail="GOOGLE_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")

    analysis_id = str(uuid.uuid4())
    video_bytes = await file.read()
    video_name = file.filename

    # v8.1: íŒŒì¼ í¬ê¸° ì œí•œ
    if len(video_bytes) > MAX_UPLOAD_SIZE:
        logger.warning("upload_rejected filename=%s size=%d max=%d", video_name, len(video_bytes), MAX_UPLOAD_SIZE)
        raise HTTPException(status_code=413, detail=f"íŒŒì¼ í¬ê¸°ê°€ ì œí•œ({MAX_UPLOAD_SIZE // (1024*1024)}MB)ì„ ì´ˆê³¼í•©ë‹ˆë‹¤")

    logger.info("upload_accepted id=%s filename=%s size_mb=%.1f", analysis_id, video_name, len(video_bytes) / (1024*1024))

    # Insert into DB
    with _get_db() as conn:
        cur = conn.cursor()
        cur.execute(
            "INSERT INTO analyses (id, video_name, status, progress, message) VALUES (%s, %s, %s, %s, %s)",
            (analysis_id, video_name, "processing", 10, "Gemini ë¶„ì„ ì‹œì‘")
        )
        conn.commit()
        cur.close()

    try:
        genai.configure(api_key=GOOGLE_API_KEY)

        # Save video to temp file
        suffix = ext or ".mp4"
        with tempfile.NamedTemporaryFile(suffix=suffix, delete=False) as tmp:
            tmp.write(video_bytes)
            tmp_path = tmp.name

        # Upload to Gemini File API
        _update_analysis(analysis_id, progress=30, message="Geminiì— ë™ì˜ìƒ ì „ì†¡ ì¤‘...")
        video_file = genai.upload_file(path=tmp_path, mime_type=f"video/{suffix[1:]}")

        # Wait for processing
        _update_analysis(analysis_id, progress=40, message="ë™ì˜ìƒ ì²˜ë¦¬ ëŒ€ê¸° ì¤‘...")
        import time as _time
        while video_file.state.name == "PROCESSING":
            _time.sleep(5)
            video_file = genai.get_file(video_file.name)

        if video_file.state.name == "FAILED":
            raise RuntimeError(f"Gemini ë™ì˜ìƒ ì²˜ë¦¬ ì‹¤íŒ¨: {video_file.state.name}")

        # Run 7-dimension analysis
        _update_analysis(analysis_id, progress=60, message="AI ìˆ˜ì—… ë¶„ì„ ì¤‘...")
        model = genai.GenerativeModel(model_name="gemini-2.0-flash")
        response = model.generate_content(
            [video_file, EVALUATION_PROMPT],
            generation_config=genai.GenerationConfig(response_mime_type="application/json")
        )

        # Parse result
        result_text = response.text.strip()
        if "```json" in result_text:
            result_text = result_text.split("```json")[1].split("```")[0]
        elif "```" in result_text:
            result_text = result_text.split("```")[1].split("```")[0]

        result = json.loads(result_text)

        # Save to DB
        with _get_db() as conn:
            cur = conn.cursor()
            cur.execute(
                """UPDATE analyses SET status=%s, progress=%s, message=%s,
                   total_score=%s, grade=%s, result_json=%s, completed_at=CURRENT_TIMESTAMP
                   WHERE id=%s""",
                ("completed", 100, "ë¶„ì„ ì™„ë£Œ",
                 result.get("total_score", 0), result.get("grade", ""),
                 json.dumps(result, ensure_ascii=False), analysis_id)
            )
            conn.commit()
            cur.close()

        _analysis_cache[analysis_id] = {
            "status": "completed", "progress": 100, "message": "ë¶„ì„ ì™„ë£Œ",
            "result": result
        }

        # Cleanup
        try:
            os.unlink(tmp_path)
            genai.delete_file(video_file.name)
        except Exception:
            pass

        return {
            "id": analysis_id,
            "status": "completed",
            "progress": 100,
            "message": "ë¶„ì„ ì™„ë£Œ",
            "created_at": datetime.now().isoformat(),
            **result
        }

    except Exception as e:
        _update_analysis(analysis_id, status="failed", progress=0, message=f"ë¶„ì„ ì‹¤íŒ¨: {str(e)[:200]}")
        raise HTTPException(status_code=500, detail=f"ë¶„ì„ ì‹¤íŒ¨: {str(e)[:300]}")


@analysis_router.get("/{analysis_id}")
async def get_analysis_status(analysis_id: str):
    """ë¶„ì„ ìƒíƒœ ì¡°íšŒ"""
    # Check cache first
    if analysis_id in _analysis_cache:
        cache = _analysis_cache[analysis_id]
        return {
            "id": analysis_id,
            "status": cache.get("status", "pending"),
            "progress": cache.get("progress", 0),
            "message": cache.get("message", "")
        }

    # Fall back to DB
    with _get_db() as conn:
        cur = conn.cursor()
        cur.execute("SELECT id, status, progress, message, created_at, completed_at FROM analyses WHERE id=%s", (analysis_id,))
        row = cur.fetchone()
        cur.close()

    if not row:
        raise HTTPException(status_code=404, detail="ë¶„ì„ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")

    return {
        "id": row[0], "status": row[1], "progress": row[2], "message": row[3],
        "created_at": str(row[4]) if row[4] else None,
        "completed_at": str(row[5]) if row[5] else None
    }


@analysis_router.get("/{analysis_id}/result")
async def get_analysis_result(analysis_id: str):
    """ë¶„ì„ ê²°ê³¼ ì¡°íšŒ"""
    # Check cache
    if analysis_id in _analysis_cache and "result" in _analysis_cache[analysis_id]:
        result = _analysis_cache[analysis_id]["result"]
        return {
            "id": analysis_id,
            "video_name": "",
            **result
        }

    # Fall back to DB
    with _get_db() as conn:
        cur = conn.cursor()
        cur.execute("SELECT video_name, status, result_json FROM analyses WHERE id=%s", (analysis_id,))
        row = cur.fetchone()
        cur.close()

    if not row:
        raise HTTPException(status_code=404, detail="ë¶„ì„ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
    if row[1] != "completed":
        raise HTTPException(status_code=400, detail="ë¶„ì„ì´ ì•„ì§ ì™„ë£Œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")

    result = json.loads(row[2]) if row[2] else {}
    return {
        "id": analysis_id,
        "video_name": row[0],
        **result
    }


# â”€â”€â”€ App â”€â”€â”€
app = FastAPI(
    title="GAIM Lab API",
    description="GAIM Lab ì¸ì¦ + ìˆ˜ì—…ë¶„ì„ ì„œë¹„ìŠ¤ (Cloud Run + Cloud SQL + Gemini)",
    version=APP_VERSION,
    docs_url="/api/docs",
    redoc_url="/api/redoc"
)

# v8.1: Rate Limiter í†µí•©
if HAS_SLOWAPI:
    app.state.limiter = _limiter
    app.add_exception_handler(RateLimitExceeded, _rate_limit_exceeded_handler)
    logger.info("rate_limiter enabled=slowapi")
else:
    logger.warning("rate_limiter disabled=slowapi_not_installed")

app.add_middleware(
    CORSMiddleware,
    allow_origins=[
        "http://localhost:3000",
        "http://localhost:5173",
        "http://localhost:5174",
        "https://edu-data.github.io",
    ],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

app.include_router(router, prefix="/api/v1", tags=["ì¸ì¦"])
app.include_router(analysis_router, prefix="/api/v1", tags=["ë¶„ì„"])


@app.get("/")
async def root():
    return {"name": "GAIM Lab API", "version": APP_VERSION, "status": "running", "db": "cloud-sql", "analysis": "gemini-2.0-flash"}


@app.get("/health")
async def health_check():
    return {"status": "healthy"}
