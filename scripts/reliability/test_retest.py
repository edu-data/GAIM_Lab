"""
GAIM Lab v8.0 â€” ê²€ì‚¬-ì¬ê²€ì‚¬ ì‹ ë¢°ë„ (Test-Retest Reliability)

ë™ì¼ ì˜ìƒì„ ë™ì¼ ë²„ì „ì—ì„œ NíšŒ ë¶„ì„í•˜ì—¬ ê²°ê³¼ì˜ ì¼ê´€ì„±ì„ ê²€ì¦í•©ë‹ˆë‹¤.

ì‚¬ìš©ë²•:
    python scripts/reliability/test_retest.py --video video/20251209_142648.mp4 --runs 3
    python scripts/reliability/test_retest.py --db data/gaim_lab.db  # ê¸°ì¡´ DBì—ì„œ ì¤‘ë³µ ë¶„ì„ ì¶”ì¶œ

ì¶œë ¥:
    - ì´ì  Pearson r, ICC
    - ì°¨ì›ë³„ Pearson r
    - Â±3ì , Â±5ì  ì¼ì¹˜ìœ¨
    - data/reliability/test_retest_v8.csv
    - data/reliability/test_retest_report.html
"""

import sys
import os
import json
import argparse
import sqlite3
from pathlib import Path
from datetime import datetime
from collections import defaultdict

import numpy as np

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ sys.pathì— ì¶”ê°€
PROJECT_ROOT = Path(__file__).resolve().parent.parent.parent
sys.path.insert(0, str(PROJECT_ROOT))


def pearson_r(x, y):
    """í”¼ì–´ìŠ¨ ìƒê´€ê³„ìˆ˜ ê³„ì‚°"""
    if len(x) < 2:
        return float('nan')
    x = np.array(x, dtype=float)
    y = np.array(y, dtype=float)
    if np.std(x) == 0 or np.std(y) == 0:
        return float('nan')
    return float(np.corrcoef(x, y)[0, 1])


def icc_two_way(scores_matrix):
    """ICC(2,1) â€” 2-way random, single measures
    
    scores_matrix: (n_subjects, n_raters) 2D array
    """
    scores = np.array(scores_matrix, dtype=float)
    n, k = scores.shape
    if n < 2 or k < 2:
        return float('nan')
    
    # í‰ê· 
    grand_mean = scores.mean()
    row_means = scores.mean(axis=1)
    col_means = scores.mean(axis=0)
    
    # ë¶„ì‚° ìš”ì†Œ
    ss_total = np.sum((scores - grand_mean) ** 2)
    ss_rows = k * np.sum((row_means - grand_mean) ** 2)
    ss_cols = n * np.sum((col_means - grand_mean) ** 2)
    ss_error = ss_total - ss_rows - ss_cols
    
    # í‰ê·  ì œê³±
    ms_rows = ss_rows / (n - 1)
    ms_cols = ss_cols / (k - 1)
    ms_error = ss_error / ((n - 1) * (k - 1))
    
    # ICC(2,1)
    denom = ms_rows + (k - 1) * ms_error + k * (ms_cols - ms_error) / n
    if denom == 0:
        return float('nan')
    
    icc = (ms_rows - ms_error) / denom
    return float(icc)


def agreement_rate(scores1, scores2, threshold=3):
    """Â±thresholdì  ì¼ì¹˜ìœ¨"""
    if len(scores1) == 0:
        return 0.0
    diffs = np.abs(np.array(scores1) - np.array(scores2))
    return float(np.mean(diffs <= threshold) * 100)


def extract_from_db(db_path: str):
    """ê¸°ì¡´ DBì—ì„œ ë™ì¼ ì˜ìƒì˜ ì¤‘ë³µ ë¶„ì„ ê²°ê³¼ ì¶”ì¶œ"""
    conn = sqlite3.connect(db_path)
    conn.row_factory = sqlite3.Row
    
    # ë™ì¼ video_pathë¥¼ ê°€ì§„ ë¶„ì„ ê²°ê³¼ë¥¼ ê·¸ë£¹ë³„ë¡œ ì¶”ì¶œ
    rows = conn.execute("""
        SELECT video_path, total_score, dimensions_json, created_at
        FROM analyses
        WHERE total_score IS NOT NULL
        ORDER BY video_path, created_at
    """).fetchall()
    conn.close()
    
    groups = defaultdict(list)
    for row in rows:
        video = row['video_path'] or 'unknown'
        # video_pathì—ì„œ íŒŒì¼ëª…ë§Œ ì¶”ì¶œ
        video_key = Path(video).stem
        score = row['total_score']
        dims = json.loads(row['dimensions_json']) if row['dimensions_json'] else {}
        groups[video_key].append({
            'total_score': score,
            'dimensions': dims,
            'created_at': row['created_at']
        })
    
    return groups


def compute_reliability(groups: dict):
    """ì‹ ë¢°ë„ ì§€í‘œ ê³„ì‚°
    
    groups: {video_key: [{'total_score': ..., 'dimensions': {...}}, ...]}
    """
    # 2íšŒ ì´ìƒ ë¶„ì„ëœ ì˜ìƒë§Œ í•„í„°
    paired = {k: v for k, v in groups.items() if len(v) >= 2}
    
    if not paired:
        return {
            'error': '2íšŒ ì´ìƒ ë¶„ì„ëœ ì˜ìƒì´ ì—†ìŠµë‹ˆë‹¤. --runs ì˜µì…˜ìœ¼ë¡œ ë°˜ë³µ ë¶„ì„ì„ ì‹¤í–‰í•˜ì„¸ìš”.',
            'total_pairs': 0,
        }
    
    # ì²« ë²ˆì§¸ì™€ ë‘ ë²ˆì§¸ ë¶„ì„ ê²°ê³¼ë¥¼ ë¹„êµ (Test-Retest)
    scores_run1 = []
    scores_run2 = []
    dim_scores = defaultdict(lambda: {'run1': [], 'run2': []})
    
    for video_key, runs in paired.items():
        run1 = runs[0]
        run2 = runs[1]
        
        scores_run1.append(run1['total_score'])
        scores_run2.append(run2['total_score'])
        
        # ì°¨ì›ë³„ ì ìˆ˜
        for dim_name, dim_data in run1.get('dimensions', {}).items():
            score1 = dim_data if isinstance(dim_data, (int, float)) else dim_data.get('score', 0)
            score2 = 0
            if dim_name in run2.get('dimensions', {}):
                d2 = run2['dimensions'][dim_name]
                score2 = d2 if isinstance(d2, (int, float)) else d2.get('score', 0)
            dim_scores[dim_name]['run1'].append(score1)
            dim_scores[dim_name]['run2'].append(score2)
    
    # ì´ì  ë¶„ì„
    r_total = pearson_r(scores_run1, scores_run2)
    
    # ICC ê³„ì‚° (ëª¨ë“  pairedì˜ ì´ì )
    icc_matrix = np.array([scores_run1, scores_run2]).T  # (n_videos, 2_runs)
    icc_value = icc_two_way(icc_matrix)
    
    # ì¼ì¹˜ìœ¨
    agree_3 = agreement_rate(scores_run1, scores_run2, threshold=3)
    agree_5 = agreement_rate(scores_run1, scores_run2, threshold=5)
    
    # ì°¨ì›ë³„ ìƒê´€
    dim_reliability = {}
    for dim_name, data in dim_scores.items():
        r = pearson_r(data['run1'], data['run2'])
        dim_reliability[dim_name] = {
            'pearson_r': round(r, 4) if not np.isnan(r) else None,
            'n_pairs': len(data['run1']),
        }
    
    # MAD (í‰ê·  ì ˆëŒ€ í¸ì°¨)
    diffs = np.abs(np.array(scores_run1) - np.array(scores_run2))
    mad = float(np.mean(diffs))
    
    return {
        'version': '8.0.0',
        'timestamp': datetime.now().isoformat(),
        'total_pairs': len(paired),
        'total_videos_analyzed': sum(len(v) for v in groups.values()),
        'total_score': {
            'pearson_r': round(r_total, 4) if not np.isnan(r_total) else None,
            'icc_2_1': round(icc_value, 4) if not np.isnan(icc_value) else None,
            'mad': round(mad, 2),
            'agreement_3pt': round(agree_3, 1),
            'agreement_5pt': round(agree_5, 1),
        },
        'dimension_reliability': dim_reliability,
        'interpretation': {
            'pearson_r': interpret_r(r_total),
            'icc': interpret_icc(icc_value),
            'agreement_3pt': 'í•©ê²©' if agree_3 >= 70 else 'ë¯¸ë‹¬',
        },
        'targets': {
            'pearson_r': '>= 0.80',
            'agreement_3pt': '>= 70%',
        },
    }


def interpret_r(r):
    """Pearson r í•´ì„"""
    if np.isnan(r):
        return 'ê³„ì‚° ë¶ˆê°€'
    if r >= 0.90:
        return 'ë§¤ìš° ë†’ìŒ (Excellent)'
    elif r >= 0.80:
        return 'ë†’ìŒ (Good) âœ…'
    elif r >= 0.70:
        return 'í—ˆìš© (Acceptable)'
    elif r >= 0.60:
        return 'ì˜ì‹¬ (Questionable)'
    else:
        return 'ë‚®ìŒ (Poor) âŒ'


def interpret_icc(icc):
    """ICC í•´ì„ (Cicchetti, 1994 ê¸°ì¤€)"""
    if np.isnan(icc):
        return 'ê³„ì‚° ë¶ˆê°€'
    if icc >= 0.75:
        return 'ìš°ìˆ˜ (Excellent)'
    elif icc >= 0.60:
        return 'ì–‘í˜¸ (Good)'
    elif icc >= 0.40:
        return 'ë³´í†µ (Fair)'
    else:
        return 'ë¯¸í¡ (Poor)'


def generate_html_report(results: dict, output_path: Path):
    """HTML ë¦¬í¬íŠ¸ ìƒì„±"""
    ts = results.get('total_score', {})
    dims = results.get('dimension_reliability', {})
    interp = results.get('interpretation', {})
    
    dim_rows = ""
    for name, data in dims.items():
        r_val = data.get('pearson_r', 'N/A')
        r_str = f"{r_val:.4f}" if isinstance(r_val, float) else str(r_val)
        dim_rows += f"<tr><td>{name}</td><td>{r_str}</td><td>{data.get('n_pairs', 0)}</td></tr>\n"
    
    html = f"""<!DOCTYPE html>
<html lang="ko">
<head>
    <meta charset="UTF-8">
    <title>GAIM Lab v8.0 â€” ê²€ì‚¬-ì¬ê²€ì‚¬ ì‹ ë¢°ë„ ë³´ê³ ì„œ</title>
    <style>
        body {{ font-family: 'Segoe UI', sans-serif; max-width: 800px; margin: 2rem auto; padding: 1rem; background: #0f172a; color: #e2e8f0; }}
        h1 {{ color: #818cf8; border-bottom: 2px solid #334155; padding-bottom: 0.5rem; }}
        h2 {{ color: #a5b4fc; margin-top: 2rem; }}
        table {{ width: 100%; border-collapse: collapse; margin: 1rem 0; }}
        th, td {{ padding: 0.75rem; text-align: left; border-bottom: 1px solid #334155; }}
        th {{ background: #1e293b; color: #94a3b8; font-weight: 600; }}
        .metric {{ font-size: 2rem; font-weight: 700; }}
        .good {{ color: #34d399; }}
        .warn {{ color: #fbbf24; }}
        .bad {{ color: #f87171; }}
        .card {{ background: #1e293b; border-radius: 1rem; padding: 1.5rem; margin: 1rem 0; }}
        .grid {{ display: grid; grid-template-columns: repeat(3, 1fr); gap: 1rem; }}
        .interpretation {{ font-size: 0.9rem; color: #94a3b8; }}
    </style>
</head>
<body>
    <h1>ğŸ” ê²€ì‚¬-ì¬ê²€ì‚¬ ì‹ ë¢°ë„ ë³´ê³ ì„œ</h1>
    <p>GAIM Lab v{results.get('version', '8.0.0')} Â· {results.get('timestamp', '')[:10]} Â· ë¶„ì„ ìŒ: {results.get('total_pairs', 0)}ê°œ</p>
    
    <h2>ğŸ“Š ì´ì  ì‹ ë¢°ë„</h2>
    <div class="grid">
        <div class="card">
            <div class="interpretation">Pearson r</div>
            <div class="metric {'good' if (ts.get('pearson_r') or 0) >= 0.80 else 'warn' if (ts.get('pearson_r') or 0) >= 0.60 else 'bad'}">{ts.get('pearson_r', 'N/A')}</div>
            <div class="interpretation">{interp.get('pearson_r', '')}</div>
        </div>
        <div class="card">
            <div class="interpretation">ICC(2,1)</div>
            <div class="metric {'good' if (ts.get('icc_2_1') or 0) >= 0.75 else 'warn' if (ts.get('icc_2_1') or 0) >= 0.60 else 'bad'}">{ts.get('icc_2_1', 'N/A')}</div>
            <div class="interpretation">{interp.get('icc', '')}</div>
        </div>
        <div class="card">
            <div class="interpretation">Â±3ì  ì¼ì¹˜ìœ¨</div>
            <div class="metric {'good' if (ts.get('agreement_3pt') or 0) >= 70 else 'bad'}">{ts.get('agreement_3pt', 'N/A')}%</div>
            <div class="interpretation">ëª©í‘œ: â‰¥ 70%</div>
        </div>
    </div>
    
    <div class="card">
        <p><strong>MAD (í‰ê·  ì ˆëŒ€ í¸ì°¨):</strong> {ts.get('mad', 'N/A')}ì </p>
        <p><strong>Â±5ì  ì¼ì¹˜ìœ¨:</strong> {ts.get('agreement_5pt', 'N/A')}%</p>
    </div>
    
    <h2>ğŸ“ ì°¨ì›ë³„ ì‹ ë¢°ë„</h2>
    <table>
        <tr><th>ì°¨ì›</th><th>Pearson r</th><th>ë¶„ì„ ìŒ</th></tr>
        {dim_rows}
    </table>
    
    <h2>ğŸ¯ ëª©í‘œ ë‹¬ì„± ì—¬ë¶€</h2>
    <table>
        <tr><th>ì§€í‘œ</th><th>í˜„ì¬</th><th>ëª©í‘œ</th><th>íŒì •</th></tr>
        <tr>
            <td>Pearson r</td>
            <td>{ts.get('pearson_r', 'N/A')}</td>
            <td>â‰¥ 0.80</td>
            <td>{'âœ…' if (ts.get('pearson_r') or 0) >= 0.80 else 'âŒ'}</td>
        </tr>
        <tr>
            <td>Â±3ì  ì¼ì¹˜ìœ¨</td>
            <td>{ts.get('agreement_3pt', 'N/A')}%</td>
            <td>â‰¥ 70%</td>
            <td>{'âœ…' if (ts.get('agreement_3pt') or 0) >= 70 else 'âŒ'}</td>
        </tr>
    </table>
</body>
</html>"""
    
    output_path.parent.mkdir(parents=True, exist_ok=True)
    output_path.write_text(html, encoding='utf-8')
    print(f"[âœ…] HTML ë¦¬í¬íŠ¸ ì €ì¥: {output_path}")


def main():
    parser = argparse.ArgumentParser(description='GAIM Lab ê²€ì‚¬-ì¬ê²€ì‚¬ ì‹ ë¢°ë„ ë¶„ì„')
    parser.add_argument('--db', type=str, default='data/gaim_lab.db',
                        help='SQLite DB ê²½ë¡œ (ê¸°ì¡´ ë¶„ì„ ê²°ê³¼ì—ì„œ ì¶”ì¶œ)')
    parser.add_argument('--video', type=str, default=None,
                        help='ë°˜ë³µ ë¶„ì„í•  ì˜ìƒ ê²½ë¡œ (ìƒˆë¡œ ë¶„ì„ ì‹¤í–‰)')
    parser.add_argument('--runs', type=int, default=2,
                        help='ë°˜ë³µ ë¶„ì„ íšŸìˆ˜ (--videoì™€ í•¨ê»˜ ì‚¬ìš©)')
    parser.add_argument('--output', type=str, default='data/reliability',
                        help='ì¶œë ¥ ë””ë ‰í† ë¦¬')
    args = parser.parse_args()
    
    output_dir = PROJECT_ROOT / args.output
    output_dir.mkdir(parents=True, exist_ok=True)
    
    db_path = PROJECT_ROOT / args.db
    
    if args.video:
        # TODO: ë°˜ë³µ ë¶„ì„ ì‹¤í–‰ í›„ DBì— ì €ì¥
        print(f"[INFO] ì˜ìƒ {args.video}ë¥¼ {args.runs}íšŒ ë°˜ë³µ ë¶„ì„í•©ë‹ˆë‹¤...")
        print("[WARN] ë°˜ë³µ ë¶„ì„ ì‹¤í–‰ì€ ì•„ì§ êµ¬í˜„ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. --db ì˜µì…˜ìœ¼ë¡œ ê¸°ì¡´ ê²°ê³¼ë¥¼ ë¶„ì„í•˜ì„¸ìš”.")
        return
    
    if not db_path.exists():
        print(f"[ERROR] DB íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {db_path}")
        print("[TIP] ë¨¼ì € ë°°ì¹˜ ë¶„ì„ì„ 2íšŒ ì´ìƒ ì‹¤í–‰í•˜ì„¸ìš”.")
        return
    
    print(f"[INFO] DBì—ì„œ ë¶„ì„ ê²°ê³¼ ì¶”ì¶œ: {db_path}")
    groups = extract_from_db(str(db_path))
    
    print(f"[INFO] ì´ {len(groups)}ê°œ ì˜ìƒ, {sum(len(v) for v in groups.values())}ê°œ ë¶„ì„ ê²°ê³¼")
    
    results = compute_reliability(groups)
    
    if 'error' in results:
        print(f"[ERROR] {results['error']}")
        return
    
    # ê²°ê³¼ ì¶œë ¥
    ts = results['total_score']
    print(f"\n{'='*50}")
    print(f"ğŸ“Š ê²€ì‚¬-ì¬ê²€ì‚¬ ì‹ ë¢°ë„ ê²°ê³¼ (v{results['version']})")
    print(f"{'='*50}")
    print(f"ë¶„ì„ ìŒ: {results['total_pairs']}ê°œ")
    print(f"Pearson r: {ts['pearson_r']}  ({results['interpretation']['pearson_r']})")
    print(f"ICC(2,1):  {ts['icc_2_1']}  ({results['interpretation']['icc']})")
    print(f"MAD:       {ts['mad']}ì ")
    print(f"Â±3ì  ì¼ì¹˜: {ts['agreement_3pt']}%  ({results['interpretation']['agreement_3pt']})")
    print(f"Â±5ì  ì¼ì¹˜: {ts['agreement_5pt']}%")
    
    # CSV ì €ì¥
    csv_path = output_dir / 'test_retest_v8.csv'
    import csv
    with open(csv_path, 'w', newline='', encoding='utf-8') as f:
        writer = csv.writer(f)
        writer.writerow(['Metric', 'Value', 'Interpretation'])
        writer.writerow(['Pearson r', ts['pearson_r'], results['interpretation']['pearson_r']])
        writer.writerow(['ICC(2,1)', ts['icc_2_1'], results['interpretation']['icc']])
        writer.writerow(['MAD', ts['mad'], ''])
        writer.writerow(['Â±3pt Agreement', f"{ts['agreement_3pt']}%", results['interpretation']['agreement_3pt']])
        writer.writerow(['Â±5pt Agreement', f"{ts['agreement_5pt']}%", ''])
    print(f"\n[âœ…] CSV ì €ì¥: {csv_path}")
    
    # JSON ì €ì¥
    json_path = output_dir / 'test_retest_v8.json'
    with open(json_path, 'w', encoding='utf-8') as f:
        json.dump(results, f, ensure_ascii=False, indent=2)
    print(f"[âœ…] JSON ì €ì¥: {json_path}")
    
    # HTML ë¦¬í¬íŠ¸
    html_path = output_dir / 'test_retest_report.html'
    generate_html_report(results, html_path)


if __name__ == '__main__':
    main()
